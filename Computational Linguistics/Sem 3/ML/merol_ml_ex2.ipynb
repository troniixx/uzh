{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQJiiyqZe0a2"
   },
   "source": [
    "# Exercise 2: Pytorch\n",
    "\n",
    "You can work in pairs or individually.\n",
    "\n",
    "Upload your solution on OLAT before the deadline: **Friday, 8th November 2014,  at 12:15**.\n",
    "\n",
    "If you have any questions, post them on OLAT.\n",
    "\n",
    "**Submission Format**\n",
    "- Filename: **olatnameStudent1_olatnameStudent2_ml_ex2.ipynb**\n",
    "- Include the names of **both team members** in the block below.\n",
    "- If you have multiple files, place your file(s) in a compressed folder (zip).\n",
    "\n",
    "\n",
    "Good luck! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q1Dw1XrfJUg"
   },
   "source": [
    "---\n",
    "Group Members:\n",
    "\n",
    "Mert Erol, 20-915-245\n",
    "\n",
    "#### please ignore the \"type: ignore\" comments, its so that my linter doesnt produce random warnings\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "1Bhgg_3JM6ur"
   },
   "outputs": [],
   "source": [
    "import torch # type: ignore\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.nn.functional as F # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEgs5e_qfVYH"
   },
   "source": [
    "## Task 1: Tensor Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28XdcX6gip-k"
   },
   "source": [
    "### Task 1.1 Squeeze and Unsqueeze\n",
    "- The first task: for the first three blocks, explain ONLY squeeze and unsqueeze dimension in SIMPLE and SHORT sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zf8TO5SJbvEi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 1, 4, 1, 3)\n",
    "x = torch.squeeze(x)\n",
    "# squeeze removes dimensions of size 1 from the shape of the tensor\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1mMtCG_pbxn2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "x = torch.unsqueeze(x, 0) # add a dimension of size to the shape at index 0\n",
    "x = torch.unsqueeze(x, -1) # add a dimension of size to the shape at the last index\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ydXbBAUpb35M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 1, 4)\n",
    "x = torch.squeeze(x, 2) # remove dimension of size 1 at index 2\n",
    "x = torch.unsqueeze(x, 1) # add dimension of size 1 to the shape at index 1\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Op9GztaFb_3F"
   },
   "source": [
    "- The second task is to use squeeze and unsqueeze functions to achieve the target dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bfoGL754b4DY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starting shape: (3, 1, 4, 1)\n",
    "# Target shape: (1, 3, 4, 1, 1)\n",
    "x = torch.randn(3, 1, 4, 1)\n",
    "x = torch.squeeze(x, 1)\n",
    "x = torch.unsqueeze(x, 0)\n",
    "x = torch.unsqueeze(x, -1)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "legbljCDqkAU"
   },
   "source": [
    "### Task 1.2 Batch Matrix Multiplication\n",
    "Given the following operations involving batch matrix multiplication (BMM)\n",
    "- fill in the code (the correct dimension for d)\n",
    "- answer questions.\n",
    "\n",
    "You can find information about batch matrix multiplication here:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.bmm.html\n",
    "\n",
    "https://stackoverflow.com/questions/50826644/why-do-we-do-batch-matrix-matrix-product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyREfDMJcOxr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x:  torch.Size([64, 128, 512])\n",
      "shape of d:  torch.Size([64, 512, 9])\n",
      "shape of y:  torch.Size([64, 128, 9])\n"
     ]
    }
   ],
   "source": [
    "# Mini-batch size of 64\n",
    "a = torch.randn(64, 128, 256)   # [batch_size, seq_length, embedding_dim]\n",
    "b = torch.randn(64, 256, 512)   # [batch_size, embedding_dim, hidden_dim]\n",
    "\n",
    "# First BMM operation\n",
    "x = torch.bmm(a, b)             # DONE: What's the shape? Calculate it!\n",
    "print(\"shape of x: \", x.shape)\n",
    "\n",
    "# Create tensor d with correct dimensions\n",
    "d = torch.randn(64, 512, 9)   # DONE: Fill in the correct dimensions\n",
    "print(\"shape of d: \", d.shape)\n",
    "\n",
    "# Second BMM operation\n",
    "y = torch.bmm(x, d)             # Target shape: [64, 128, 9]\n",
    "                                # (batch_size, seq_length, output_dim)\n",
    "print(\"shape of y: \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rga3vt3icPp9"
   },
   "source": [
    "1. What is the shape of intermediate tensor x?\n",
    "\n",
    "      torch.Size([64, 128, 512])\n",
    "\n",
    "2. Fill in the shape of tensor d. Explain why you did so according to bmm.\n",
    "   \n",
    "      Tensor d should have the shape [64, 512, 9] to be compatible with the next bmm operation. This is because x has a shape      [64,  128, 512], so when performing y = torch.bmm(x, d), the 512 in x and d align\n",
    "\n",
    "3. Think: Why does this sequence of operations make sense in the context of\n",
    "   deep learning (hint: think about sequence processing)? Then guess and answer: what might seq_length and embedding_dim mean? How about the output dimension of y? (Points will be given for all guesses that are relevant to Text/Speech/Images/Sciences etc.)\n",
    "\n",
    "      Operations could represent transformations on a sequence of data, where seq_length represents the number of steps in a sequence (like words in a sentence for NLP tasks) and embedding_dim or hidden_dim represents the dimensionality of the embeddings. The final output dimension might represent a classification into 9 categories or classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZUhBTxTqrF_"
   },
   "source": [
    "###Task 1.3: Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvdP2BaKFeNi"
   },
   "source": [
    "Take a closer look at the code below, finish it (TODO) and then answer the questions. You can add print statements to get insight into the individual steps and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CClnoyZxFjqZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4952, -0.7276, -1.2611, -0.3340,  1.2518],\n",
       "        [-1.6660, -0.4927,  1.5976,  2.1014,  0.0643],\n",
       "        [-1.0812,  0.1321,  1.6172,  0.1853,  1.2440],\n",
       "        [ 0.9381, -1.6118,  0.5916,  0.7331,  0.5981],\n",
       "        [-0.8053, -0.6769,  1.2444,  0.0452,  1.8524]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have a dataset of 10 tokens, and each token is represented by a vector with a dimensionality of 5.\n",
    "vocab_size = 10 #DONE\n",
    "embedding_dim = 5 #DONE\n",
    "\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "x = torch.LongTensor([1, 3, 5, 7, 9])\n",
    "\n",
    "embedded_x = embedding_layer(x)\n",
    "embedded_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izMr6-0tI23R"
   },
   "source": [
    "TODO: Answer the following questions: (I have no idea what happened with markdown here)\n",
    "- a) What is the purpose of the embedding layer in neural networks?\n",
    "\n",
    "        layer maps input information from a high-dimensional to a lower-dimensional space, allowing the network to learn more about the relationship between inputs and to process the data more efficiently\n",
    "\n",
    "- b) What is the role of 'vocab_size' and 'embedding_dim' in the 'nn.Embedding' layer?\n",
    "\n",
    "        nn.Embedding(size of the dictionary of embeddings, the size of each embedding vector)\n",
    "        \n",
    "- c) What happens if you try to embed a category that is out of the range defined by vocab_size in the nn.Embedding layer? Give an example of an out of range input value.\n",
    "\n",
    "        the values need to be in [0, vocab_size-1]. If we use a value thats negative or >(vocab_size-1) it will raise an Error.\n",
    "        e.g \n",
    "\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "\n",
    "        vocab_size = 10  # Assume a vocabulary size of 10\n",
    "        embedding_dim = 5\n",
    "        embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        input_tensor = torch.tensor([10])  # 10 is out of range\n",
    "        output = embedding_layer(input_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBK-tWE4M8dH"
   },
   "source": [
    "## Task 2: Network Parameters\n",
    "\n",
    "Imagine you're training a neural network for a 10-class classification problem  that takes an input vector of size 236. You implement 2 hidden layers with 472 neurons each. You don't learn any bias terms.\n",
    "<br>\n",
    "\n",
    " 1) How many different parameters does the neural network contain?\n",
    "    \n",
    "    236 * 472 + 472^2 + 472*10 = 338'896\n",
    "\n",
    "<br> <br>\n",
    "1) What's the difference between parameters and hyper-parameters? Name 3 different hyper-parameters and explain their role inside a neural network.\n",
    "    \n",
    "    Parameter: Internal values learned by the network during training like weights in the neural connections. These are adjusted in response to the data to minimize the loss function and improve the models predictions.\n",
    "\n",
    "    Hyperparameter: External configs that are set before training, like the architecture of the model or the learning rate. These are not learned from the data but instead manually adjusted to optimize performance.\n",
    "\n",
    "    e.g hyperparams: \n",
    "        - learning rate\n",
    "        - batch size\n",
    "        - number of epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPfZrlK0q0uZ"
   },
   "source": [
    "## Task 3: Pytorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeInKnh4rpRG"
   },
   "source": [
    "###Task 3.1: Realize the following model in PyTorch:\n",
    "  - [ ] Realize matrices as linear layers.\n",
    "  - [ ] Create an instance of your model.\n",
    "  - [ ] Apply it to $\\mathbf{x}$, defined in the second code cell.\n",
    "  - [ ] Determine the Cross-Entropy loss.\n",
    "\n",
    "**Model Equations:**\n",
    "\n",
    "- $\\mathbf{e}=\\mathbf{E}\\mathbf{x}$\n",
    "- $\\mathbf{h}=\\sigma(\\mathbf{W}\\mathbf{e}+\\mathbf{b})$\n",
    "- $\\mathbf{z}=\\mathbf{U}\\mathbf{h}+\\mathbf{b}$\n",
    "- $\\hat{\\mathbf{y}}=\\mathbf{z}$\n",
    "\n",
    "**Details:**\n",
    "\n",
    "- We are performing a classification task with **4 classes**.\n",
    "- $\\mathbf{x}$ is a batch of 4 integers that represent some tokens.\n",
    "- $\\mathbf{E}$ is a 8 x 6 embedding layer, realized with PyTorch functionality.\n",
    "- $\\mathbf{W}$ and $\\mathbf{U}$ are weight matrices. Both layers learn bias terms. The output dimension of $\\mathbf{W}$ is 10.\n",
    "- Activation function $\\sigma$ is ReLU.\n",
    "- Model output is 4 logits per token (raw values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lee4dwrAsHrz"
   },
   "source": [
    "Note: Don't change any of the existing code, only add your solutions where it's indicated (TODO statements). Print statements can be placed wherever you need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMCgn6tNsKTU"
   },
   "outputs": [],
   "source": [
    "import torch # type: ignore\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(8, 6) #DONE\n",
    "        self.W = nn.Linear(6, 10)#DONE\n",
    "        self.U = nn.Linear(10, 4) #DONE\n",
    "        self.relu = nn.ReLU() #DONE\n",
    "\n",
    "    def forward(self,x):\n",
    "        #DONE: ... (as many lines as you need)\n",
    "        e = self.embedding(x)\n",
    "        h = self.relu(self.W(e))\n",
    "        z = self.U(h)\n",
    "\n",
    "        return z #DONE:...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11x7OafSs7VG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: tensor([[ 0.3125,  0.0869,  0.2802, -0.1106],\n",
      "        [-0.2266, -0.4833,  0.0509, -0.4157],\n",
      "        [-0.3728, -0.2066, -0.1796, -0.3994],\n",
      "        [-0.1099, -0.2404, -0.3024, -0.1897]], grad_fn=<AddmmBackward0>)\n",
      "loss: 1.3744735717773438\n"
     ]
    }
   ],
   "source": [
    "X=torch.tensor([1,2,3,7],dtype=torch.long)\n",
    "y=torch.tensor([1,0,1,3],dtype=torch.long)\n",
    "\n",
    "model = Net() #DONE\n",
    "output = model(X) #DONE\n",
    "print(f'model output: {output}')\n",
    "\n",
    "#DONE: determine the loss\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss() #DONE\n",
    "loss = loss_function(output, y) #DONE\n",
    "print(f'loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "808ndtJeAdGZ"
   },
   "source": [
    "### Task 3.2\n",
    "\n",
    "Take another look at the cells above.\n",
    "\n",
    "- Is it a binary or a multiclass classification task?\n",
    "    - multiclass\n",
    "- Why is there no activation function applied to the output? (Hint: check the documentation for Cross Entropy Loss) TODO\n",
    "    - CrossEntropyLoss expects raw logits as input and internally applies the softmax activation function. Applying an external activation function would double up which give incorrect results\n",
    "- What is the vocabulary size of this model? TODO\n",
    "    - 8\n",
    "- What do the numbers in $\\mathbf{y}$ represent? TODO\n",
    "    - class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESjPGt7_BO4a"
   },
   "source": [
    "## Task 4 (Bidirectional Self-)Attention\n",
    "Given a simple sentence \"he likes cats\" and the following weight matrices:\n",
    "- Weight matrix for Query ($W_q$)\n",
    "- Weight matrix for Key ($W_k$)\n",
    "\n",
    "Dimensionalities: (important!)\n",
    "- the dimensionality of input is [sentence length, d]\n",
    "- d stands for hidden embeddings\n",
    "- the dimensionality of weight matrices should be [d, d_k]\n",
    "- **from above, you can see that d_k has nothing to do with input x.**\n",
    "\n",
    "You have two tasks.\n",
    "- Follow the steps to fill in the code - calculate the weight matrix.\n",
    "- Look at the weight matrix and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ppuPNhU_BQCk"
   },
   "outputs": [],
   "source": [
    "# Don't change this block, just read and run\n",
    "# Weight matrices\n",
    "Wq = torch.tensor([[0.5, 2.0],\n",
    "                    [3.0, 1.5]])\n",
    "\n",
    "Wk = torch.tensor([[1.0, 0.4],\n",
    "                    [0.6, 1.2]])\n",
    "\n",
    "# Word embeddings for \"he likes cats\"\n",
    "x = torch.tensor([[1.0, 2.0],  # \"he\"\n",
    "                    [2.0, 1.0],  # \"likes\"\n",
    "                    [1.5, 1.5]]) # \"cats\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CEDMwOwdDSo"
   },
   "source": [
    "Follow the steps to compute attention weights and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Op78EGaWdCup"
   },
   "outputs": [],
   "source": [
    "# Step 1: calculate Q and K\n",
    "Q = torch.matmul(x, Wq) # DONE\n",
    "K = torch.matmul(x, Wk) # DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHcPA8KbdG0J"
   },
   "outputs": [],
   "source": [
    "# Step 2: Compute attention scores\n",
    "# hint1: d_k has nothing to do with d_x, but instead, it is related to the weight matrix k.\n",
    "# hint2: to compute the scores, you need to transpose K to compute the scores)\n",
    "import math\n",
    "\n",
    "d_k = K.size(1) # DONE\n",
    "scores = torch.matmul(Q, K.T) # DONE\n",
    "scores_scaled = scores / math.sqrt(d_k) #DONE, here you divide the scores by ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFGKKcArUIKe"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F63v0hHudIIK"
   },
   "outputs": [],
   "source": [
    "# Step 3.1:\n",
    "# It is always a good habitude to read documentation. Always read documentation.\n",
    "# Find the documentation in torch on how you can calculate the variance of a tensor, and paste the link here\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.var.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paA8rDPxdK5a"
   },
   "outputs": [],
   "source": [
    "# Step 3.2:\n",
    "# Read the documentation\n",
    "# Use what you find in the documentation and calculate the variance of scores and scores_scaled\n",
    "# Hint: It should be a very simple code\n",
    "\n",
    "var_scores = torch.var(scores, dim = None) # DONE\n",
    "var_scores_scaled = torch.var(scores_scaled, dim = None) # DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "zCFmwiJ4dLri"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0000)\n"
     ]
    }
   ],
   "source": [
    "# Step 3.3\n",
    "# the code below gives you the ratio of var_scores and var_scores_scaled\n",
    "ratio = var_scores / var_scores_scaled\n",
    "print(ratio)\n",
    "\n",
    "# Answer: what number the ratio is close to?\n",
    "\n",
    "# The ratio is close to 2. This indicates that scaling the scores by sqrt(dk) reduces their variance by approximately a factor of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Du4orBRwdOg3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5047, 0.1876, 0.3077],\n",
       "        [0.6624, 0.0915, 0.2461],\n",
       "        [0.5874, 0.1331, 0.2796]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Apply softmax to get attention weights\n",
    "weights = F.softmax(scores_scaled, dim = 1) # DONE\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba0JZ2rTeBgO"
   },
   "source": [
    "TODO: Answer the questions below\n",
    "\n",
    "a) What do the values in the first row of attention weights represent?\n",
    "    he to he // he to likes // he to cats\n",
    "\n",
    "b) Look at the last row of weights - what does each number tell us?\n",
    "    cats to he // cats to likes // cats to cats\n",
    "\n",
    "c) Which row or column you should look at if you want to find out which word pays most attention to \"likes\"? and what is the word?\n",
    "    second column and the word is \"he\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APvWmymY-4Sn"
   },
   "source": [
    "## Task 5: Training Optimization Problems\n",
    "\n",
    "### Task 5.1:\n",
    "\n",
    "For each scenario, choose between GD, SGD and mini-batch GD.\n",
    "\n",
    "a) You are training a deep neural network. You have a lot of training samples but limited GPU memory. Now you want to have some stability during training and enable parallel processing.\n",
    "\n",
    "mini-batch GD\n",
    "\n",
    "b) You're training a model with data points coming in in real time, and you want to process them immediately.\n",
    "\n",
    "SGD\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvXAh2LETj4x"
   },
   "source": [
    "### Task 5.2:\n",
    "\n",
    "You're training a neural model. After several epochs you notice that the loss decreases very slowly, so you increase the learning rate. Now the loss fluctuates significantly. What were the issues (before and after changing the leaning rate)?\n",
    "\n",
    "**#TODO**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
