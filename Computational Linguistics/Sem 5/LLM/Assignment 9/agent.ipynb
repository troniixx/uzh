{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKPZb42NXjmP"
      },
      "source": [
        "# Assignment 9\n",
        "## Task 2.2 – Agent with a song-lyrics tool\n",
        "\n",
        "In this part of the assignment you will build a **simple agentic system** using the `smolagents` library.\n",
        "\n",
        "First, make sure to read the [guided tour](https://huggingface.co/docs/smolagents/v1.23.0/en/guided_tour) of the library. It contains explanations about everything you will need to complete your tasks.\n",
        "\n",
        "**Goal.** Your agent should be able to provide the user with *song lyrics* by:\n",
        "1. Calling a custom retrieval tool `get_lyrics(title, artist=None)`, accepting a song title and optionally the artist name as inputs. The tool looks up lyrics in a Hugging Face dataset and return it as a string.\n",
        "2. Using an LLM (namely gemini-2.5-flash-lite) via `smolagents` to decide when to call the tool and to return the retrieved lyrics to the user exactly as stored in the dataset.\n",
        "\n",
        "If the artist is not provided, your tool should search by title only and return the best match.\n",
        "\n",
        "**Example.**  \n",
        "If the user asks:\n",
        "\n",
        "> “Give me the lyrics of 'Imagine' by John Lennon.”\n",
        "\n",
        "the agent should:\n",
        "1. Call `get_lyrics(title=\"Imagine\", artist=\"John Lennon\")` **OR** `get_lyrics(title=\"Imagine\", artist=None)` if no artist was provided in the user prompt  \n",
        "2. Receive the raw lyrics text as tool output  \n",
        "3. Read those lyrics and generate an answer like “Here are the Lyrics for the song 'Imagine' by John Lennon: Imagine there's no heaven It's easy if you try No hell below us Above us, only sky ...”\n",
        "\n",
        "\n",
        "You will:\n",
        "- inspect the Hugging Face lyrics dataset,\n",
        "- implement the `get_lyrics` tool,\n",
        "- plug it into a `ToolCallingAgent`,\n",
        "- and experiment with a few queries to analyse how well the agent uses the tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS0cGwyhYfDu"
      },
      "source": [
        "Start by installing the necessary packages for this assigment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v8fU80R6Wq2z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: smolagents[openai] in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.31.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (0.35.1)\n",
            "Requirement already satisfied: requests>=2.32.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (2.32.4)\n",
            "Requirement already satisfied: rich>=13.9.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (14.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (3.1.6)\n",
            "Requirement already satisfied: pillow>=10.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (11.3.0)\n",
            "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (1.1.1)\n",
            "Requirement already satisfied: openai>=1.58.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (2.8.1)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (2025.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (1.1.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2>=3.1.4->smolagents[openai]) (3.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.58.1->smolagents[openai]) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.58.1->smolagents[openai]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.58.1->smolagents[openai]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.58.1->smolagents[openai]) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.58.1->smolagents[openai]) (2.12.5)\n",
            "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.58.1->smolagents[openai]) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai>=1.58.1->smolagents[openai]) (3.10)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai]) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai]) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.3->smolagents[openai]) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.3->smolagents[openai]) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=13.9.4->smolagents[openai]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=13.9.4->smolagents[openai]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents[openai]) (0.1.2)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai]) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai]) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.3->smolagents[openai]) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.3->smolagents[openai]) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=13.9.4->smolagents[openai]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=13.9.4->smolagents[openai]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents[openai]) (0.1.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.1.1)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.2.6)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.3.1)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.35.1)\n",
            "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.21.0)\n",
            "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.1.1)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.2.6)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.3.1)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.35.1)\n",
            "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.21.0)\n",
            "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install \"smolagents[openai]\"; pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUf7OIvMZIfK"
      },
      "source": [
        "### Step 1 – Explore the Hugging Face dataset\n",
        "\n",
        "\n",
        "Load the [Spotify million song dataset](https://huggingface.co/datasets/vishnupriyavr/spotify-million-song-dataset) from HuggingFace and take a look at it.\n",
        "Understanding which columns exist (e.g. title, artist, lyrics) will make it much easier to implement `get_lyrics`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Huf71Sysc20z"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['artist', 'song', 'link', 'text'],\n",
            "    num_rows: 57650\n",
            "})\n",
            "{'artist': 'ABBA', 'song': \"Ahe's My Kind Of Girl\", 'link': '/a/abba/ahes+my+kind+of+girl_20598417.html', 'text': \"Look at her face, it's a wonderful face  \\r\\nAnd it means something special to me  \\r\\nLook at the way that she smiles when she sees me  \\r\\nHow lucky can one fellow be?  \\r\\n  \\r\\nShe's just my kind of girl, she makes me feel fine  \\r\\nWho could ever believe that she could be mine?  \\r\\nShe's just my kind of girl, without her I'm blue  \\r\\nAnd if she ever leaves me what could I do, what could I do?  \\r\\n  \\r\\nAnd when we go for a walk in the park  \\r\\nAnd she holds me and squeezes my hand  \\r\\nWe'll go on walking for hours and talking  \\r\\nAbout all the things that we plan  \\r\\n  \\r\\nShe's just my kind of girl, she makes me feel fine  \\r\\nWho could ever believe that she could be mine?  \\r\\nShe's just my kind of girl, without her I'm blue  \\r\\nAnd if she ever leaves me what could I do, what could I do?\\r\\n\\r\\n\"}\n",
            "{'artist': 'ABBA', 'song': 'Andante, Andante', 'link': '/a/abba/andante+andante_20002708.html', 'text': \"Take it easy with me, please  \\r\\nTouch me gently like a summer evening breeze  \\r\\nTake your time, make it slow  \\r\\nAndante, Andante  \\r\\nJust let the feeling grow  \\r\\n  \\r\\nMake your fingers soft and light  \\r\\nLet your body be the velvet of the night  \\r\\nTouch my soul, you know how  \\r\\nAndante, Andante  \\r\\nGo slowly with me now  \\r\\n  \\r\\nI'm your music  \\r\\n(I am your music and I am your song)  \\r\\nI'm your song  \\r\\n(I am your music and I am your song)  \\r\\nPlay me time and time again and make me strong  \\r\\n(Play me again 'cause you're making me strong)  \\r\\nMake me sing, make me sound  \\r\\n(You make me sing and you make me)  \\r\\nAndante, Andante  \\r\\nTread lightly on my ground  \\r\\nAndante, Andante  \\r\\nOh please don't let me down  \\r\\n  \\r\\nThere's a shimmer in your eyes  \\r\\nLike the feeling of a thousand butterflies  \\r\\nPlease don't talk, go on, play  \\r\\nAndante, Andante  \\r\\nAnd let me float away  \\r\\n  \\r\\nI'm your music  \\r\\n(I am your music and I am your song)  \\r\\nI'm your song  \\r\\n(I am your music and I am your song)  \\r\\nPlay me time and time again and make me strong  \\r\\n(Play me again 'cause you're making me strong)  \\r\\nMake me sing, make me sound  \\r\\n(You make me sing and you make me)  \\r\\nAndante, Andante  \\r\\nTread lightly on my ground  \\r\\nAndante, Andante  \\r\\nOh please don't let me down  \\r\\n  \\r\\nMake me sing, make me sound  \\r\\n(You make me sing and you make me)  \\r\\nAndante, Andante  \\r\\nTread lightly on my ground  \\r\\nAndante, Andante  \\r\\nOh please don't let me down  \\r\\nAndante, Andante  \\r\\nOh please don't let me down\\r\\n\\r\\n\"}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"vishnupriyavr/spotify-million-song-dataset\", split=\"train\")\n",
        "\n",
        "# Inspect the dataset structure and a first example.\n",
        "print(dataset)\n",
        "print(dataset[0])\n",
        "print(dataset[1])\n",
        "\n",
        "# You can also try:\n",
        "# dataset.column_names\n",
        "# dataset[0].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1-FM1qBd8Jp"
      },
      "source": [
        "### Step 2 - Implement the custom tool\n",
        "\n",
        "Implement the `get_lyrics` function to match the description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uoyalgCfeNgs"
      },
      "outputs": [],
      "source": [
        "from smolagents import tool\n",
        "from typing import Optional\n",
        "\n",
        "@tool\n",
        "def get_lyrics(title: str, artist: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Return the lyrics of the given song, exactly as stored in the dataset.\n",
        "\n",
        "    The agent's goal is to retrieve and output the lyrics exactly\n",
        "    as stored in the dataset. Matching is case-insensitive.\n",
        "\n",
        "    Args:\n",
        "        title: Song title (e.g., \"Imagine\").\n",
        "        artist: Optional artist name (e.g., \"John Lennon\"). If not\n",
        "            provided, the search is done only by title.\n",
        "\n",
        "    Returns:\n",
        "        The raw lyrics text exactly as stored in the dataset, or a human-\n",
        "        friendly message if no match is found.\n",
        "    \"\"\"\n",
        "    # Normalize inputs for case-insensitive comparison\n",
        "    title_norm = title.strip().lower()\n",
        "    artist_norm = artist.strip().lower() if artist else None\n",
        "\n",
        "    # Try to find a matching entry in the dataset\n",
        "    for entry in dataset:\n",
        "        # NOTE: column names in this dataset\n",
        "        entry_title = (entry.get(\"song\") or \"\").strip().lower()\n",
        "        entry_artist = (entry.get(\"artist\") or \"\").strip().lower()\n",
        "        entry_lyrics = (entry.get(\"text\") or \"\")\n",
        "\n",
        "        if artist_norm:\n",
        "            if entry_title == title_norm and entry_artist == artist_norm:\n",
        "                return entry_lyrics\n",
        "        else:\n",
        "            if entry_title == title_norm:\n",
        "                return entry_lyrics\n",
        "\n",
        "    return \"Sorry, no matching song found.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3_QgiOrf9-x"
      },
      "source": [
        "Make sure that the tool works correctly before instantiating the agent and making an API call.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rn3ydU9NgRwY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Testing: {'title': 'Imagine'}\n",
            "Output (first 300 chars):\n",
            "Imagine there's no heaven,  \n",
            "It's easy if you try,  \n",
            "No hell below us,  \n",
            "Above us only sky,  \n",
            "Imagine all the people  \n",
            "Living for today...  \n",
            "  \n",
            "Imagine there's no countries,  \n",
            "It isn't hard to do,  \n",
            "Nothing to kill or die for,  \n",
            "No religion too,  \n",
            "Imagine all the people  \n",
            "Living life in \n",
            "============================================================\n",
            "Testing: {'title': 'Imagine', 'artist': 'John Lennon'}\n",
            "Output (first 300 chars):\n",
            "Sorry, no matching song found.\n",
            "============================================================\n",
            "Testing: {'title': 'Halo'}\n",
            "Output (first 300 chars):\n",
            "Sorry, no matching song found.\n",
            "============================================================\n",
            "Testing: {'title': 'Halo'}\n",
            "Output (first 300 chars):\n",
            "Good and bad  \n",
            "I swear I've had them both, they're overrated  \n",
            "But is it fun  \n",
            "When you get hold of one  \n",
            "Some gone bad  \n",
            "And some gone back  \n",
            "Good ones all get taken I'm callin' bluff  \n",
            "You ain't strong enough  \n",
            "  \n",
            "Wait and pray you'll pick on me  \n",
            "the day I raise my hand  \n",
            "Guess that I'\n",
            "============================================================\n",
            "Testing: {'title': 'Nonexistent Song'}\n",
            "Output (first 300 chars):\n",
            "Good and bad  \n",
            "I swear I've had them both, they're overrated  \n",
            "But is it fun  \n",
            "When you get hold of one  \n",
            "Some gone bad  \n",
            "And some gone back  \n",
            "Good ones all get taken I'm callin' bluff  \n",
            "You ain't strong enough  \n",
            "  \n",
            "Wait and pray you'll pick on me  \n",
            "the day I raise my hand  \n",
            "Guess that I'\n",
            "============================================================\n",
            "Testing: {'title': 'Nonexistent Song'}\n",
            "Output (first 300 chars):\n",
            "Sorry, no matching song found.\n",
            "Output (first 300 chars):\n",
            "Sorry, no matching song found.\n"
          ]
        }
      ],
      "source": [
        "# Test AFTER you implement get_lyrics()\n",
        "\n",
        "test_queries = [\n",
        "    {\"title\": \"Imagine\"},\n",
        "    {\"title\": \"Imagine\", \"artist\": \"John Lennon\"},\n",
        "    {\"title\": \"Halo\"},  \n",
        "    {\"title\": \"Nonexistent Song\"},\n",
        "]\n",
        "\n",
        "for q in test_queries:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Testing:\", q)\n",
        "    try:\n",
        "        out = get_lyrics(**q)\n",
        "        print(\"Output (first 300 chars):\")\n",
        "        print(out[:300] if isinstance(out, str) else out)\n",
        "    except NotImplementedError:\n",
        "        print(\"Implement get_lyrics() first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zva4QvyjhLil"
      },
      "source": [
        "### Step 3 - Load the model\n",
        "\n",
        "To generate your API key, follow these instructions:\n",
        "1. Make sure you are connected to the UZH network. Note: Eduroam is not sufficient; you need to use either UZH VPN or the uzh Wifi network.\n",
        "2. Log in to the [LiteLLM gateway server](http://172.23.206.243:4000) from our course, using your UZH email and the password you set up during Assignment 1. Note: If you forgot your password, send an email to giovanni.rocci@uzh.ch, I will provide you with a password reset link.\n",
        "3. Once you are logged-in, visit http://172.23.206.243:4000/ui/?page=api-keys\n",
        "    - Click on the blue button \"create new key\"\n",
        "    - Do not select any Team\n",
        "    - Choose a key name\n",
        "    - Under \"Models\", select “All Team models”\n",
        "    - Create the key, copy it and paste it in the cell below under `api_key`\n",
        "\n",
        "**Note**: do not change parameters `model_id` and `api_base` in the model definition. You are free to experiment using additional parameters related to generation (such as `temperature`, `max_tokens`, `top_p`, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y84JnY-Khg8k"
      },
      "outputs": [],
      "source": [
        "from smolagents import OpenAIModel\n",
        "\n",
        "with open(\"key.txt\", \"r\") as f:\n",
        "    api_key = f.read().strip()\n",
        "\n",
        "model = OpenAIModel(\n",
        "    model_id=\"gemini-2.5-flash-lite\",\n",
        "    api_key=api_key,\n",
        "    api_base=\"http://172.23.206.243:4000/\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df2SlM7Iikjx"
      },
      "source": [
        "### Step 4 - Build and call the agent\n",
        "\n",
        "Based on the example from the `smolagents` guided tour, provide the agent with the right arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oegnyof3ip6m"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Give me the lyrics of 'California'</span>                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIModel - gemini-2.5-flash-lite ───────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mGive me the lyrics of 'California'\u001b[0m                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIModel - gemini-2.5-flash-lite \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│ Calling tool: 'get_lyrics' with arguments: {'title': 'California'}                                              │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│ Calling tool: 'get_lyrics' with arguments: {'title': 'California'}                                              │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: By Bob Dylan  \n",
              "  \n",
              "I'm goin' down south,  \n",
              "'Neath the borderline.  \n",
              "I'm goin' down south,  \n",
              "'Neath the borderline.  \n",
              "Some fat momma  \n",
              "Kissed my mouth one time.  \n",
              "  \n",
              "Well, I needed it this morning  \n",
              "Without a shadow of doubt.  \n",
              "My suitcase is packed,  \n",
              "My clothes are hangin' out.  \n",
              "  \n",
              "San Francisco's fine,  \n",
              "You sure get lots of sun.  \n",
              "San Francisco is fine.  \n",
              "You sure get lots of sun.  \n",
              "But I'm used to four seasons,  \n",
              "California's got but one.  \n",
              "  \n",
              "Well, I got my dark sunglasses,  \n",
              "I got for good luck my black tooth.  \n",
              "I got my dark sunglasses,  \n",
              "And for good luck I got my black tooth.  \n",
              "Don't ask me nothin' about nothin',  \n",
              "I just might tell you the truth.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Observations: By Bob Dylan  \n",
              "  \n",
              "I'm goin' down south,  \n",
              "'Neath the borderline.  \n",
              "I'm goin' down south,  \n",
              "'Neath the borderline.  \n",
              "Some fat momma  \n",
              "Kissed my mouth one time.  \n",
              "  \n",
              "Well, I needed it this morning  \n",
              "Without a shadow of doubt.  \n",
              "My suitcase is packed,  \n",
              "My clothes are hangin' out.  \n",
              "  \n",
              "San Francisco's fine,  \n",
              "You sure get lots of sun.  \n",
              "San Francisco is fine.  \n",
              "You sure get lots of sun.  \n",
              "But I'm used to four seasons,  \n",
              "California's got but one.  \n",
              "  \n",
              "Well, I got my dark sunglasses,  \n",
              "I got for good luck my black tooth.  \n",
              "I got my dark sunglasses,  \n",
              "And for good luck I got my black tooth.  \n",
              "Don't ask me nothin' about nothin',  \n",
              "I just might tell you the truth.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 0.68 seconds| Input tokens: 1,149 | Output tokens: 5]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2m[Step 1: Duration 0.68 seconds| Input tokens: 1,149 | Output tokens: 5]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│ Calling tool: 'final_answer' with arguments: {'answer': \"By Bob Dylan  \\n  \\nI'm goin' down south,  \\n'Neath    │\n",
              "│ the borderline.  \\nI'm goin' down south,  \\n'Neath the borderline.  \\nSome fat momma  \\nKissed my mouth one     │\n",
              "│ time.  \\n  \\nWell, I needed it this morning  \\nWithout a shadow of doubt.  \\nMy suitcase is packed,  \\nMy       │\n",
              "│ clothes are hangin' out.  \\n  \\nSan Francisco's fine,  \\nYou sure get lots of sun.  \\nSan Francisco is fine.    │\n",
              "│ \\nYou sure get lots of sun.  \\nBut I'm used to four seasons,  \\nCalifornia's got but one.  \\n  \\nWell, I got my │\n",
              "│ dark sunglasses,  \\nI got for good luck my black tooth.  \\nI got my dark sunglasses,  \\nAnd for good luck I got │\n",
              "│ my black tooth.  \\nDon't ask me nothin' about nothin',  \\nI just might tell you the truth.\"}                    │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ],
            "text/plain": [
              "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│ Calling tool: 'final_answer' with arguments: {'answer': \"By Bob Dylan  \\n  \\nI'm goin' down south,  \\n'Neath    │\n",
              "│ the borderline.  \\nI'm goin' down south,  \\n'Neath the borderline.  \\nSome fat momma  \\nKissed my mouth one     │\n",
              "│ time.  \\n  \\nWell, I needed it this morning  \\nWithout a shadow of doubt.  \\nMy suitcase is packed,  \\nMy       │\n",
              "│ clothes are hangin' out.  \\n  \\nSan Francisco's fine,  \\nYou sure get lots of sun.  \\nSan Francisco is fine.    │\n",
              "│ \\nYou sure get lots of sun.  \\nBut I'm used to four seasons,  \\nCalifornia's got but one.  \\n  \\nWell, I got my │\n",
              "│ dark sunglasses,  \\nI got for good luck my black tooth.  \\nI got my dark sunglasses,  \\nAnd for good luck I got │\n",
              "│ my black tooth.  \\nDon't ask me nothin' about nothin',  \\nI just might tell you the truth.\"}                    │\n",
              "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: By Bob Dylan  \n",
              "  \n",
              "I'm goin' down south,  \n",
              "'Neath the borderline.  \n",
              "I'm goin' down south,  \n",
              "'Neath the borderline.  \n",
              "Some fat momma  \n",
              "Kissed my mouth one time.  \n",
              "  \n",
              "Well, I needed it this morning  \n",
              "Without a shadow of doubt.  \n",
              "My suitcase is packed,  \n",
              "My clothes are hangin' out.  \n",
              "  \n",
              "San Francisco's fine,  \n",
              "You sure get lots of sun.  \n",
              "San Francisco is fine.  \n",
              "You sure get lots of sun.  \n",
              "But I'm used to four seasons,  \n",
              "California's got but one.  \n",
              "  \n",
              "Well, I got my dark sunglasses,  \n",
              "I got for good luck my black tooth.  \n",
              "I got my dark sunglasses,  \n",
              "And for good luck I got my black tooth.  \n",
              "Don't ask me nothin' about nothin',  \n",
              "I just might tell you the truth.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Observations: By Bob Dylan  \n",
              "  \n",
              "I'm goin' down south,  \n",
              "'Neath the borderline.  \n",
              "I'm goin' down south,  \n",
              "'Neath the borderline.  \n",
              "Some fat momma  \n",
              "Kissed my mouth one time.  \n",
              "  \n",
              "Well, I needed it this morning  \n",
              "Without a shadow of doubt.  \n",
              "My suitcase is packed,  \n",
              "My clothes are hangin' out.  \n",
              "  \n",
              "San Francisco's fine,  \n",
              "You sure get lots of sun.  \n",
              "San Francisco is fine.  \n",
              "You sure get lots of sun.  \n",
              "But I'm used to four seasons,  \n",
              "California's got but one.  \n",
              "  \n",
              "Well, I got my dark sunglasses,  \n",
              "I got for good luck my black tooth.  \n",
              "I got my dark sunglasses,  \n",
              "And for good luck I got my black tooth.  \n",
              "Don't ask me nothin' about nothin',  \n",
              "I just might tell you the truth.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: By Bob Dylan  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">I'm goin' down south,  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">'Neath the borderline.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">I'm goin' down south,  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">'Neath the borderline.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Some fat momma  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Kissed my mouth one time.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Well, I needed it this morning  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Without a shadow of doubt.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">My suitcase is packed,  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">My clothes are hangin' out.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">San Francisco's fine,  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">You sure get lots of sun.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">San Francisco is fine.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">You sure get lots of sun.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">But I'm used to four seasons,  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">California's got but one.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Well, I got my dark sunglasses,  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">I got for good luck my black tooth.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">I got my dark sunglasses,  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">And for good luck I got my black tooth.  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Don't ask me nothin' about nothin',  </span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">I just might tell you the truth.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;38;2;212;183;2mFinal answer: By Bob Dylan  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2m  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mI'm goin' down south,  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2m'Neath the borderline.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mI'm goin' down south,  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2m'Neath the borderline.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mSome fat momma  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mKissed my mouth one time.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2m  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mWell, I needed it this morning  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mWithout a shadow of doubt.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mMy suitcase is packed,  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mMy clothes are hangin' out.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2m  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mSan Francisco's fine,  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mYou sure get lots of sun.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mSan Francisco is fine.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mYou sure get lots of sun.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mBut I'm used to four seasons,  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mCalifornia's got but one.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2m  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mWell, I got my dark sunglasses,  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mI got for good luck my black tooth.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mI got my dark sunglasses,  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mAnd for good luck I got my black tooth.  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mDon't ask me nothin' about nothin',  \u001b[0m\n",
              "\u001b[1;38;2;212;183;2mI just might tell you the truth.\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 1.12 seconds| Input tokens: 2,604 | Output tokens: 223]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2m[Step 2: Duration 1.12 seconds| Input tokens: 2,604 | Output tokens: 223]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "\"By Bob Dylan  \\n  \\nI'm goin' down south,  \\n'Neath the borderline.  \\nI'm goin' down south,  \\n'Neath the borderline.  \\nSome fat momma  \\nKissed my mouth one time.  \\n  \\nWell, I needed it this morning  \\nWithout a shadow of doubt.  \\nMy suitcase is packed,  \\nMy clothes are hangin' out.  \\n  \\nSan Francisco's fine,  \\nYou sure get lots of sun.  \\nSan Francisco is fine.  \\nYou sure get lots of sun.  \\nBut I'm used to four seasons,  \\nCalifornia's got but one.  \\n  \\nWell, I got my dark sunglasses,  \\nI got for good luck my black tooth.  \\nI got my dark sunglasses,  \\nAnd for good luck I got my black tooth.  \\nDon't ask me nothin' about nothin',  \\nI just might tell you the truth.\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from smolagents import ToolCallingAgent\n",
        "\n",
        "# TODO: insert the arguments for your agent\n",
        "agent = ToolCallingAgent(tools=[get_lyrics], model=model)\n",
        "\n",
        "\n",
        "#agent.run(\"Give me the lyrics of 'Imagine' by John Lennon.\")\n",
        "# agent.run(\"Give me the lyrics of 'Halo'.\")\n",
        "# agent.run(\"Give me the lyrics of 'Motive' by EAZ\") # Not in dataset\n",
        "agent.run(\"Give me the lyrics of 'California'\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq7hP3tpo7cC"
      },
      "source": [
        "### Step 5 - Explore your agent's behaviour\n",
        "\n",
        "1. **Ambiguous titles**\n",
        "   - What happens when you omit the artist information for a song that shares the name with another famous song?\n",
        "   - How do you think these cases should be handled?\n",
        "\n",
        "2. **Failure modes**\n",
        "   - Try a query where the song is **not** in the dataset (e.g. a very obscure title, or nonsense).  \n",
        "   - How does the agent respond? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxm4hIOPpOeM"
      },
      "source": [
        "1. Our guess is that it works thorugh the dataset in alphabetical order and it just picks the first one. TO handle these cases, it should let the user know that there are multiple songs with that title and also ask the user what information they want (e.g. all the songs, specific song from artist, random artist, etc.)\n",
        "\n",
        "\n",
        "```bash\n",
        "╭──────────────────────────────────────────────────── New run ────────────────────────────────────────────────────╮\n",
        "│                                                                                                                 │\n",
        "│ Give me the lyrics of 'California'                                                                              │\n",
        "│                                                                                                                 │\n",
        "╰─ OpenAIModel - gemini-2.5-flash-lite ───────────────────────────────────────────────────────────────────────────╯\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ Step 1 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
        "│ Calling tool: 'get_lyrics' with arguments: {'title': 'California'}                                              │\n",
        "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
        "Observations: By Bob Dylan  \n",
        "  \n",
        "I'm goin' down south,  \n",
        "'Neath the borderline.  \n",
        "I'm goin' down south,  \n",
        "'Neath the borderline.  \n",
        "Some fat momma  \n",
        "Kissed my mouth one time.  \n",
        "  \n",
        "Well, I needed it this morning  \n",
        "Without a shadow of doubt.  \n",
        "My suitcase is packed,  \n",
        "My clothes are hangin' out.  \n",
        "  \n",
        "San Francisco's fine,  \n",
        "You sure get lots of sun.  \n",
        "San Francisco is fine.  \n",
        "You sure get lots of sun.  \n",
        "But I'm used to four seasons,  \n",
        "California's got but one.  \n",
        "  \n",
        "Well, I got my dark sunglasses,  \n",
        "I got for good luck my black tooth.  \n",
        "I got my dark sunglasses,  \n",
        "And for good luck I got my black tooth.  \n",
        "Don't ask me nothin' about nothin',  \n",
        "I just might tell you the truth.\n",
        "[Step 1: Duration 0.68 seconds| Input tokens: 1,149 | Output tokens: 5]\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ Step 2 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
        "│ Calling tool: 'final_answer' with arguments: {'answer': \"By Bob Dylan  \\n  \\nI'm goin' down south,  \\n'Neath    │\n",
        "│ the borderline.  \\nI'm goin' down south,  \\n'Neath the borderline.  \\nSome fat momma  \\nKissed my mouth one     │\n",
        "│ time.  \\n  \\nWell, I needed it this morning  \\nWithout a shadow of doubt.  \\nMy suitcase is packed,  \\nMy       │\n",
        "│ clothes are hangin' out.  \\n  \\nSan Francisco's fine,  \\nYou sure get lots of sun.  \\nSan Francisco is fine.    │\n",
        "│ \\nYou sure get lots of sun.  \\nBut I'm used to four seasons,  \\nCalifornia's got but one.  \\n  \\nWell, I got my │\n",
        "│ dark sunglasses,  \\nI got for good luck my black tooth.  \\nI got my dark sunglasses,  \\nAnd for good luck I got │\n",
        "│ my black tooth.  \\nDon't ask me nothin' about nothin',  \\nI just might tell you the truth.\"}                    │\n",
        "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
        "Observations: By Bob Dylan  \n",
        "  \n",
        "I'm goin' down south,  \n",
        "'Neath the borderline.  \n",
        "I'm goin' down south,  \n",
        "'Neath the borderline.  \n",
        "Some fat momma  \n",
        "Kissed my mouth one time.  \n",
        "  \n",
        "Well, I needed it this morning  \n",
        "Without a shadow of doubt.  \n",
        "My suitcase is packed,  \n",
        "My clothes are hangin' out.  \n",
        "  \n",
        "San Francisco's fine,  \n",
        "You sure get lots of sun.  \n",
        "San Francisco is fine.  \n",
        "You sure get lots of sun.  \n",
        "But I'm used to four seasons,  \n",
        "California's got but one.  \n",
        "  \n",
        "Well, I got my dark sunglasses,  \n",
        "I got for good luck my black tooth.  \n",
        "I got my dark sunglasses,  \n",
        "And for good luck I got my black tooth.  \n",
        "Don't ask me nothin' about nothin',  \n",
        "I just might tell you the truth.\n",
        "Final answer: By Bob Dylan  \n",
        "  \n",
        "I'm goin' down south,  \n",
        "'Neath the borderline.  \n",
        "I'm goin' down south,  \n",
        "'Neath the borderline.  \n",
        "Some fat momma  \n",
        "Kissed my mouth one time.  \n",
        "  \n",
        "Well, I needed it this morning  \n",
        "Without a shadow of doubt.  \n",
        "My suitcase is packed,  \n",
        "My clothes are hangin' out.  \n",
        "  \n",
        "San Francisco's fine,  \n",
        "You sure get lots of sun.  \n",
        "San Francisco is fine.  \n",
        "You sure get lots of sun.  \n",
        "But I'm used to four seasons,  \n",
        "California's got but one.  \n",
        "  \n",
        "Well, I got my dark sunglasses,  \n",
        "I got for good luck my black tooth.  \n",
        "I got my dark sunglasses,  \n",
        "And for good luck I got my black tooth.  \n",
        "Don't ask me nothin' about nothin',  \n",
        "I just might tell you the truth.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. It does what its supposed to do and tells us that the song is not in the dataset.\n",
        "\n",
        "``` bash\n",
        "╭──────────────────────────────────────────────────── New run ────────────────────────────────────────────────────╮\n",
        "│                                                                                                                 │\n",
        "│ Give me the lyrics of 'Motive' by EAZ                                                                           │\n",
        "│                                                                                                                 │\n",
        "╰─ OpenAIModel - gemini-2.5-flash-lite ───────────────────────────────────────────────────────────────────────────╯\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ Step 1 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
        "│ Calling tool: 'get_lyrics' with arguments: {'title': 'Motive', 'artist': 'EAZ'}                                 │\n",
        "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
        "Observations: Sorry, no matching song found.\n",
        "[Step 1: Duration 1.21 seconds| Input tokens: 1,153 | Output tokens: 9]\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ Step 2 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
        "│ Calling tool: 'final_answer' with arguments: {'answer': \"Sorry, I couldn't find the lyrics for 'Motive' by      │\n",
        "│ EAZ.\"}                                                                                                          │\n",
        "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
        "Observations: Sorry, I couldn't find the lyrics for 'Motive' by EAZ.\n",
        "Final answer: Sorry, I couldn't find the lyrics for 'Motive' by EAZ.\n",
        "[Step 2: Duration 1.11 seconds| Input tokens: 2,388 | Output tokens: 31]\n",
        "\"Sorry, I couldn't find the lyrics for 'Motive' by EAZ.\"\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
