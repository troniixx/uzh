{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKPZb42NXjmP"
      },
      "source": [
        "# Assignment 9\n",
        "## Task 2.2 – Agent with a song-lyrics tool\n",
        "\n",
        "In this part of the assignment you will build a **simple agentic system** using the `smolagents` library.\n",
        "\n",
        "First, make sure to read the [guided tour](https://huggingface.co/docs/smolagents/v1.23.0/en/guided_tour) of the library. It contains explanations about everything you will need to complete your tasks.\n",
        "\n",
        "**Goal.** Your agent should be able to provide the user with *song lyrics* by:\n",
        "1. Calling a custom retrieval tool `get_lyrics(title, artist=None)`, accepting a song title and optionally the artist name as inputs. The tool looks up lyrics in a Hugging Face dataset and return it as a string.\n",
        "2. Using an LLM (namely gemini-2.5-flash-lite) via `smolagents` to decide when to call the tool and to return the retrieved lyrics to the user exactly as stored in the dataset.\n",
        "\n",
        "If the artist is not provided, your tool should search by title only and return the best match.\n",
        "\n",
        "**Example.**  \n",
        "If the user asks:\n",
        "\n",
        "> “Give me the lyrics of 'Imagine' by John Lennon.”\n",
        "\n",
        "the agent should:\n",
        "1. Call `get_lyrics(title=\"Imagine\", artist=\"John Lennon\")` **OR** `get_lyrics(title=\"Imagine\", artist=None)` if no artist was provided in the user prompt  \n",
        "2. Receive the raw lyrics text as tool output  \n",
        "3. Read those lyrics and generate an answer like “Here are the Lyrics for the song 'Imagine' by John Lennon: Imagine there's no heaven It's easy if you try No hell below us Above us, only sky ...”\n",
        "\n",
        "\n",
        "You will:\n",
        "- inspect the Hugging Face lyrics dataset,\n",
        "- implement the `get_lyrics` tool,\n",
        "- plug it into a `ToolCallingAgent`,\n",
        "- and experiment with a few queries to analyse how well the agent uses the tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS0cGwyhYfDu"
      },
      "source": [
        "Start by installing the necessary packages for this assigment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v8fU80R6Wq2z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting smolagents[openai]\n",
            "  Downloading smolagents-1.23.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.31.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (0.35.1)\n",
            "Requirement already satisfied: requests>=2.32.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (2.32.4)\n",
            "Collecting rich>=13.9.4 (from smolagents[openai])\n",
            "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: jinja2>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (3.1.6)\n",
            "Requirement already satisfied: pillow>=10.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (11.3.0)\n",
            "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smolagents[openai]) (1.1.1)\n",
            "Collecting openai>=1.58.1 (from smolagents[openai])\n",
            "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (2025.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents[openai]) (1.1.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2>=3.1.4->smolagents[openai]) (3.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.58.1->smolagents[openai]) (4.11.0)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.58.1->smolagents[openai])\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.58.1->smolagents[openai]) (0.28.1)\n",
            "Collecting jiter<1,>=0.10.0 (from openai>=1.58.1->smolagents[openai])\n",
            "  Downloading jiter-0.12.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai>=1.58.1->smolagents[openai])\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai>=1.58.1->smolagents[openai]) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai>=1.58.1->smolagents[openai]) (3.10)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (0.16.0)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai])\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai])\n",
            "  Downloading pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai])\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.3->smolagents[openai]) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.3->smolagents[openai]) (2.5.0)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=13.9.4->smolagents[openai])\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=13.9.4->smolagents[openai]) (2.19.1)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents[openai])\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading smolagents-1.23.0-py3-none-any.whl (148 kB)\n",
            "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading jiter-0.12.0-cp313-cp313-macosx_11_0_arm64.whl (318 kB)\n",
            "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "Downloading pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: typing-inspection, pydantic-core, mdurl, jiter, distro, annotated-types, pydantic, markdown-it-py, rich, openai, smolagents\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [smolagents]1\u001b[0m [openai]n-it-py]\n",
            "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.12.0 markdown-it-py-4.0.0 mdurl-0.1.2 openai-2.8.1 pydantic-2.12.5 pydantic-core-2.41.5 rich-14.2.0 smolagents-1.23.0 typing-inspection-0.4.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.1.1)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.2.6)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.3.1)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.35.1)\n",
            "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.21.0)\n",
            "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install \"smolagents[openai]\"; pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUf7OIvMZIfK"
      },
      "source": [
        "### Step 1 – Explore the Hugging Face dataset\n",
        "\n",
        "\n",
        "Load the [Spotify million song dataset](https://huggingface.co/datasets/vishnupriyavr/spotify-million-song-dataset) from HuggingFace and take a look at it.\n",
        "Understanding which columns exist (e.g. title, artist, lyrics) will make it much easier to implement `get_lyrics`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Huf71Sysc20z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['artist', 'song', 'link', 'text'],\n",
            "    num_rows: 57650\n",
            "})\n",
            "{'artist': 'ABBA', 'song': \"Ahe's My Kind Of Girl\", 'link': '/a/abba/ahes+my+kind+of+girl_20598417.html', 'text': \"Look at her face, it's a wonderful face  \\r\\nAnd it means something special to me  \\r\\nLook at the way that she smiles when she sees me  \\r\\nHow lucky can one fellow be?  \\r\\n  \\r\\nShe's just my kind of girl, she makes me feel fine  \\r\\nWho could ever believe that she could be mine?  \\r\\nShe's just my kind of girl, without her I'm blue  \\r\\nAnd if she ever leaves me what could I do, what could I do?  \\r\\n  \\r\\nAnd when we go for a walk in the park  \\r\\nAnd she holds me and squeezes my hand  \\r\\nWe'll go on walking for hours and talking  \\r\\nAbout all the things that we plan  \\r\\n  \\r\\nShe's just my kind of girl, she makes me feel fine  \\r\\nWho could ever believe that she could be mine?  \\r\\nShe's just my kind of girl, without her I'm blue  \\r\\nAnd if she ever leaves me what could I do, what could I do?\\r\\n\\r\\n\"}\n",
            "{'artist': 'ABBA', 'song': 'Andante, Andante', 'link': '/a/abba/andante+andante_20002708.html', 'text': \"Take it easy with me, please  \\r\\nTouch me gently like a summer evening breeze  \\r\\nTake your time, make it slow  \\r\\nAndante, Andante  \\r\\nJust let the feeling grow  \\r\\n  \\r\\nMake your fingers soft and light  \\r\\nLet your body be the velvet of the night  \\r\\nTouch my soul, you know how  \\r\\nAndante, Andante  \\r\\nGo slowly with me now  \\r\\n  \\r\\nI'm your music  \\r\\n(I am your music and I am your song)  \\r\\nI'm your song  \\r\\n(I am your music and I am your song)  \\r\\nPlay me time and time again and make me strong  \\r\\n(Play me again 'cause you're making me strong)  \\r\\nMake me sing, make me sound  \\r\\n(You make me sing and you make me)  \\r\\nAndante, Andante  \\r\\nTread lightly on my ground  \\r\\nAndante, Andante  \\r\\nOh please don't let me down  \\r\\n  \\r\\nThere's a shimmer in your eyes  \\r\\nLike the feeling of a thousand butterflies  \\r\\nPlease don't talk, go on, play  \\r\\nAndante, Andante  \\r\\nAnd let me float away  \\r\\n  \\r\\nI'm your music  \\r\\n(I am your music and I am your song)  \\r\\nI'm your song  \\r\\n(I am your music and I am your song)  \\r\\nPlay me time and time again and make me strong  \\r\\n(Play me again 'cause you're making me strong)  \\r\\nMake me sing, make me sound  \\r\\n(You make me sing and you make me)  \\r\\nAndante, Andante  \\r\\nTread lightly on my ground  \\r\\nAndante, Andante  \\r\\nOh please don't let me down  \\r\\n  \\r\\nMake me sing, make me sound  \\r\\n(You make me sing and you make me)  \\r\\nAndante, Andante  \\r\\nTread lightly on my ground  \\r\\nAndante, Andante  \\r\\nOh please don't let me down  \\r\\nAndante, Andante  \\r\\nOh please don't let me down\\r\\n\\r\\n\"}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"vishnupriyavr/spotify-million-song-dataset\", split=\"train\")\n",
        "\n",
        "# Inspect the dataset structure and a first example.\n",
        "print(dataset)\n",
        "print(dataset[0])\n",
        "print(dataset[1])\n",
        "\n",
        "# You can also try:\n",
        "# dataset.column_names\n",
        "# dataset[0].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1-FM1qBd8Jp"
      },
      "source": [
        "### Step 2 - Implement the custom tool\n",
        "\n",
        "Implement the `get_lyrics` function to match the description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uoyalgCfeNgs"
      },
      "outputs": [],
      "source": [
        "from smolagents import tool\n",
        "from typing import Optional\n",
        "\n",
        "@tool\n",
        "def get_lyrics(title: str, artist: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Return the lyrics of the given song, exactly as stored in the dataset.\n",
        "\n",
        "    The agent's goal is to retrieve and output the lyrics exactly\n",
        "    as stored in the dataset. Matching is case-insensitive.\n",
        "\n",
        "    Args:\n",
        "        title: Song title (e.g., \"Imagine\").\n",
        "        artist: Optional artist name (e.g., \"John Lennon\"). If not\n",
        "            provided, the search is done only by title.\n",
        "\n",
        "    Returns:\n",
        "        The raw lyrics text exactly as stored in the dataset, or a human-\n",
        "        friendly message if no match is found.\n",
        "    \"\"\"\n",
        "    # Normalize inputs for case-insensitive comparison\n",
        "    title_norm = title.strip().lower()\n",
        "    artist_norm = artist.strip().lower() if artist else None\n",
        "\n",
        "    # Try to find a matching entry in the dataset\n",
        "    for entry in dataset:\n",
        "        # NOTE: column names in this dataset\n",
        "        entry_title = (entry.get(\"song\") or \"\").strip().lower()\n",
        "        entry_artist = (entry.get(\"artist\") or \"\").strip().lower()\n",
        "        entry_lyrics = (entry.get(\"text\") or \"\")\n",
        "\n",
        "        if artist_norm:\n",
        "            if entry_title == title_norm and entry_artist == artist_norm:\n",
        "                return entry_lyrics\n",
        "        else:\n",
        "            if entry_title == title_norm:\n",
        "                return entry_lyrics\n",
        "\n",
        "    return \"Sorry, no matching song found.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3_QgiOrf9-x"
      },
      "source": [
        "Make sure that the tool works correctly before instantiating the agent and making an API call.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rn3ydU9NgRwY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Testing: {'title': 'Imagine'}\n",
            "Output (first 300 chars):\n",
            "Imagine there's no heaven,  \n",
            "It's easy if you try,  \n",
            "No hell below us,  \n",
            "Above us only sky,  \n",
            "Imagine all the people  \n",
            "Living for today...  \n",
            "  \n",
            "Imagine there's no countries,  \n",
            "It isn't hard to do,  \n",
            "Nothing to kill or die for,  \n",
            "No religion too,  \n",
            "Imagine all the people  \n",
            "Living life in \n",
            "============================================================\n",
            "Testing: {'title': 'Imagine', 'artist': 'John Lennon'}\n",
            "Output (first 300 chars):\n",
            "Sorry, no matching song found.\n",
            "============================================================\n",
            "Testing: {'title': 'Halo'}\n",
            "Output (first 300 chars):\n",
            "Good and bad  \n",
            "I swear I've had them both, they're overrated  \n",
            "But is it fun  \n",
            "When you get hold of one  \n",
            "Some gone bad  \n",
            "And some gone back  \n",
            "Good ones all get taken I'm callin' bluff  \n",
            "You ain't strong enough  \n",
            "  \n",
            "Wait and pray you'll pick on me  \n",
            "the day I raise my hand  \n",
            "Guess that I'\n",
            "============================================================\n",
            "Testing: {'title': 'Nonexistent Song'}\n",
            "Output (first 300 chars):\n",
            "Sorry, no matching song found.\n",
            "Output (first 300 chars):\n",
            "Sorry, no matching song found.\n",
            "============================================================\n",
            "Testing: {'title': 'Halo'}\n",
            "Output (first 300 chars):\n",
            "Good and bad  \n",
            "I swear I've had them both, they're overrated  \n",
            "But is it fun  \n",
            "When you get hold of one  \n",
            "Some gone bad  \n",
            "And some gone back  \n",
            "Good ones all get taken I'm callin' bluff  \n",
            "You ain't strong enough  \n",
            "  \n",
            "Wait and pray you'll pick on me  \n",
            "the day I raise my hand  \n",
            "Guess that I'\n",
            "============================================================\n",
            "Testing: {'title': 'Nonexistent Song'}\n",
            "Output (first 300 chars):\n",
            "Sorry, no matching song found.\n"
          ]
        }
      ],
      "source": [
        "# Test AFTER you implement get_lyrics()\n",
        "\n",
        "test_queries = [\n",
        "    {\"title\": \"Imagine\"},\n",
        "    {\"title\": \"Imagine\", \"artist\": \"John Lennon\"},\n",
        "    {\"title\": \"Halo\"},  \n",
        "    {\"title\": \"Nonexistent Song\"},\n",
        "]\n",
        "\n",
        "for q in test_queries:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Testing:\", q)\n",
        "    try:\n",
        "        out = get_lyrics(**q)\n",
        "        print(\"Output (first 300 chars):\")\n",
        "        print(out[:300] if isinstance(out, str) else out)\n",
        "    except NotImplementedError:\n",
        "        print(\"Implement get_lyrics() first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zva4QvyjhLil"
      },
      "source": [
        "### Step 3 - Load the model\n",
        "\n",
        "To generate your API key, follow these instructions:\n",
        "1. Make sure you are connected to the UZH network. Note: Eduroam is not sufficient; you need to use either UZH VPN or the uzh Wifi network.\n",
        "2. Log in to the [LiteLLM gateway server](http://172.23.206.243:4000) from our course, using your UZH email and the password you set up during Assignment 1. Note: If you forgot your password, send an email to giovanni.rocci@uzh.ch, I will provide you with a password reset link.\n",
        "3. Once you are logged-in, visit http://172.23.206.243:4000/ui/?page=api-keys\n",
        "    - Click on the blue button \"create new key\"\n",
        "    - Do not select any Team\n",
        "    - Choose a key name\n",
        "    - Under \"Models\", select “All Team models”\n",
        "    - Create the key, copy it and paste it in the cell below under `api_key`\n",
        "\n",
        "**Note**: do not change parameters `model_id` and `api_base` in the model definition. You are free to experiment using additional parameters related to generation (such as `temperature`, `max_tokens`, `top_p`, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y84JnY-Khg8k"
      },
      "outputs": [],
      "source": [
        "from smolagents import OpenAIModel\n",
        "\n",
        "model = OpenAIModel(\n",
        "    model_id=\"gemini-2.5-flash-lite\",\n",
        "    api_key=\"your_litellm_api_key\",\n",
        "    api_base=\"http://172.23.206.243:4000/\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df2SlM7Iikjx"
      },
      "source": [
        "### Step 4 - Build and call the agent\n",
        "\n",
        "Based on the example from the `smolagents` guided tour, provide the agent with the right arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oegnyof3ip6m"
      },
      "outputs": [],
      "source": [
        "from smolagents import ToolCallingAgent\n",
        "\n",
        "# TODO: insert the arguments for your agent\n",
        "agent = ToolCallingAgent()\n",
        "\n",
        "\n",
        "agent.run(\"Give me the lyrics of 'Imagine' by John Lennon.\")\n",
        "# agent.run(\"Give me the lyrics of 'Halo'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq7hP3tpo7cC"
      },
      "source": [
        "### Step 5 - Explore your agent's behaviour\n",
        "\n",
        "1. **Ambiguous titles**\n",
        "   - What happens when you omit the artist information for a song that shares the name with another famous song?\n",
        "   - How do you think these cases should be handled?\n",
        "\n",
        "2. **Failure modes**\n",
        "   - Try a query where the song is **not** in the dataset (e.g. a very obscure title, or nonsense).  \n",
        "   - How does the agent respond? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxm4hIOPpOeM"
      },
      "source": [
        "*your answers here*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
