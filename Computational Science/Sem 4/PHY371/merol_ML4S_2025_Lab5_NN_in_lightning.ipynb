{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Lightning\n",
    "\n",
    "This lab is design for investigating the basic architecture and parameter searching techniques in deep learning literature. We use a fundamental dataset, MNIST, with the help of PyTorch Lightning and design our model to handle image classification task.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "* You can achieve up to **20 points** for this graded notebook. The points for each task are clearly declared in the task descriptions. Fill in the missing code fragments and answer questions whenever you see this symbol: &#x1F536;. Please do not change any of the provided code. Notice that one symbol &#x1F536; does NOT mean one-line code: sometimes it can require several code of lines.\n",
    "\n",
    "* Team work is not allowed! Everybody implements his/her own code. Discussing issues with others is fine, sharing code with others is not. \n",
    "\n",
    "* If you use any code fragments found on the internet, make sure you reference them properly.\n",
    "\n",
    "* The responsible TA for this lab are **Yuchang** and **Sara**, if you have further questions please reach out to them directly: **yuchang.jiang@uzh.ch** and **sara.zoccheddu@uzh.ch**.\n",
    "\n",
    "* Since the lab sessions are specifically designed to answer your questions please make sure to attend those and only reach out if further questions pop up later.\n",
    "\n",
    "* Hand in your solution via OLAT until <span style=\"color:#4ea373\">**15.05.2025**</span>. Make sure that all cells are execute as we will not rerun any code. Any cell that is not executed will automatically result in 0 points for this task. \n",
    "</div>\n",
    "\n",
    "#### Suggestions\n",
    "\n",
    "Please install pytorch lightning packages via conda or pip before starting the lab session. You can use the tutorials of [Pytorch Lightning](https://lightning.ai/docs/pytorch/stable/notebooks/lightning_examples/mnist-hello-world.html).\n",
    "\n",
    "Please also check: [Tensorboard](https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html)\n",
    "\n",
    "For installing lightning: [Link](https://lightning.ai/pytorch-lightning)\n",
    "\n",
    "Please keep in mind that this is a valuable opportunity to develop self-learning skills. When working with a new package like PyTorch Lightning, always refer to the official documentation or search for solutions online when encountering errors, rather than immediately asking a friend or TA. This habit will greatly enhance your ability to troubleshoot and learn independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Overview\n",
    "\n",
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "1. **Datasets** <span style=\"color:#4ea373\">**[3pt]**</span>\n",
    "2. **NN Architectures** <span style=\"color:#4ea373\">**[5pt]**</span>\n",
    "2. **Experiments** <span style=\"color:#4ea373\">**[5pt]**</span>\n",
    "2. **Results** <span style=\"color:#4ea373\">**[4pt]**</span>\n",
    "2. **Conclusions** <span style=\"color:#4ea373\">**[3pt]**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Basic Machine Learning Modules\n",
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "\n",
    "# Deep Learning Modules\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "# Visualization Modules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Others\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy\n",
    "from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # You can comment out this line while debuging, not in submission!\n",
    "\n",
    "numpy.random.seed(42)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "torch.manual_seed(42)\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "DATASET_PATH = '/Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST'  # You can change them\n",
    "EXPERIMENTS_PATH = '/Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST_exp'  # You can change them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Dataset (3 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Design a DataModule for MNIST.\n",
    "- Use 80/20 % split for train/val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 10460511.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 314587.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2957766.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 6362902.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/merterol/Desktop/iMac27_github/uzh/Computational Science/Sem 4/PHY371/MNIST/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]]), tensor([5, 8, 4, 4, 4, 0, 3, 9, 1, 3, 6, 2, 1, 3, 5, 7, 4, 6, 0, 4, 8, 4, 0, 4,\n",
      "        3, 3, 4, 3, 2, 4, 2, 6, 0, 2, 8, 9, 9, 6, 8, 1, 3, 1, 8, 1, 3, 2, 9, 9,\n",
      "        5, 8, 3, 0, 5, 7, 1, 1, 5, 7, 5, 6, 1, 3, 1, 4])]\n"
     ]
    }
   ],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_folder: str = DATASET_PATH, batch_size: int = 64, num_cpu: int = 1):\n",
    "        super().__init__()\n",
    "        self.path = data_folder\n",
    "        self.batch_size = batch_size\n",
    "        self.num_cpu = num_cpu\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    \n",
    "    def prepare_data(self) -> None:\n",
    "        # 🔶 TODO: Download MNIST Data in self.path\n",
    "        MNIST(root = self.path, train=True, download=True)\n",
    "        MNIST(root = self.path, train=False, download=True)\n",
    "\n",
    "    \n",
    "    def setup(self, stage: str = 'fit') -> None:\n",
    "        # 🔶 TODO: Insert your code \n",
    "        # HINT: how to split the whole dataset into train, val sets? \n",
    "        # and how should those sets be used in different stages?\n",
    "        \n",
    "        if stage in ['fit', 'tune']:\n",
    "            full_train = MNIST(root=self.path, train=True, transform=self.transform)\n",
    "            train_size = int(0.8 * len(full_train))\n",
    "            val_size = len(full_train) - train_size\n",
    "            self.train_dataset, self.val_dataset = torch.utils.data.random_split(full_train, [train_size, val_size])\n",
    "        \n",
    "        if stage in ['fit', 'tune', 'validate']:\n",
    "            if not hasattr(self, 'val_dataset'):\n",
    "                full_train = MNIST(root=self.path, train=True, transform=self.transform)\n",
    "                train_size = int(0.8 * len(full_train))\n",
    "                val_size = len(full_train) - train_size\n",
    "                _, self.val_dataset = torch.utils.data.random_split(full_train, [train_size, val_size])\n",
    "        \n",
    "        elif stage in ['test', 'predict']:\n",
    "            self.test_dataset = MNIST(root = self.path, train = False, transform = self.transform)  # 🔶 TODO: Insert your code \n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError('Unknown Stage: {}'.format(stage))\n",
    "            \n",
    "    def train_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        return torch.utils.data.DataLoader(\n",
    "            batch_size=self.batch_size, num_workers=self.num_cpu,  # DO NOT CHANGE IN VAL/TEST LOADERS\n",
    "            dataset=self.train_dataset, shuffle=True,  # Could be changed in val/test loaders\n",
    "        )\n",
    "    def val_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        # 🔶 TODO: Insert your code\n",
    "        # HINT: check docs of 'torch.utils.data.DataLoader'.\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset = self.val_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_cpu,\n",
    "            shuffle = False,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        # 🔶 TODO: Insert your code\n",
    "        # HINT: what's the difference between 'val_dataloader' and 'test_dataloader'?\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset = self.test_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_cpu,\n",
    "            shuffle = False,\n",
    "        )\n",
    "        \n",
    "    def predict_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        return self.test_dataloader()\n",
    "\n",
    "data_module = MNISTDataModule()\n",
    "data_module.prepare_data()\n",
    "data_module.setup('fit')\n",
    "dl = data_module.train_dataloader()\n",
    "print(next(dl.__iter__()))  # DO NOT CHANGE | will be used for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Images: [B x C x H x W] =  torch.Size([64, 1, 28, 28])\n",
      "Shape of Labels: [B] =  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Do not change! Only for checking.\n",
    "print('Shape of Images: [B x C x H x W] = ', next(dl.__iter__())[0].shape)\n",
    "print('Shape of Labels: [B] = ', next(dl.__iter__())[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Neural Network Architecture (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Design an model with 3 Convolutional layers and 1 fully-connected layer, in this order:\n",
    "    - Convolution: Kernel size = 3x3, padding = 'same', number of filters = 4\n",
    "    - Convolution: Kernel size = 3x3, padding = 'same', number of filters = 8\n",
    "    - Convolution: Kernel size = 3x3, padding = 'same', number of filters = 4\n",
    "    - Linear: No Bias, num_class = 10 in MNIST Dataset\n",
    "- Use rectified linear unit (ReLU) for activation function (when necessary). \n",
    "- Initialize all the weights with `xavier_uniform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10]) torch.float32\n",
      "tensor([[-1.3407,  0.6474,  1.3574,  0.7361,  1.8476, -0.3699, -0.1215, -0.0558,\n",
      "         -0.7714, -0.3651],\n",
      "        [-1.1083,  0.7181,  1.3379,  0.8089,  2.0845, -0.8070,  0.0117,  0.3289,\n",
      "         -0.7864, -0.8928],\n",
      "        [-1.5244,  0.4468,  1.2048,  0.9522,  1.9017, -0.7932,  0.0053,  0.1596,\n",
      "         -0.7596, -0.6852],\n",
      "        [-1.5235,  0.5117,  0.9190,  0.7907,  2.2066, -0.6643, -0.2235,  0.2211,\n",
      "         -0.5628, -0.6289]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RawModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 🔶 TODO: Insert your code\n",
    "        # HINT: define model layers based on the given model design (Conv2d...)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 4, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 4, out_channels = 8, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 8, out_channels = 4, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = 4 * 28 * 28, out_features = 10),\n",
    "        )\n",
    "        \n",
    "        self.model.apply(self.initialize_weights)\n",
    "    \n",
    "    @staticmethod\n",
    "    def initialize_weights(module: torch.nn.Module) -> None:\n",
    "        # 🔶 TODO: Insert your code\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "        \n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input: torch.Tensor | dtype=torch.float | shape=[B, C, H, W]\n",
    "        Output: torch.Tensor | dtype=torch.float | shape=[B, num_class]\n",
    "        \"\"\"\n",
    "        # 🔶 TODO: Insert your code\n",
    "        return self.model(images)\n",
    "\n",
    "model = RawModel()\n",
    "with torch.no_grad():  # DO NOT REMOVE THIS LINES BELOW\n",
    "    sample_image = torch.rand(size=(4, 1, 28, 28))\n",
    "    output = model(sample_image)\n",
    "    print(output.shape, output.dtype)  \n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Experiments (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define training/validation/test step and optimizer with cross-entropy loss and `AdamW` optimizer.\n",
    "- Use accuracy scores for monitoring the experiment. (you can use multiclass accuracy from Lightning Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTExperiment(pl.LightningModule):\n",
    "    def __init__(self, learning_rate: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.model = RawModel()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.train_scores = ...  # 🔶 TODO: Insert your code\n",
    "        # HINT: define the metric used in this classification task.\n",
    "        self.validation_scores = ...  # 🔶 TODO: Insert your code\n",
    "        self.test_scores = ...  # 🔶 TODO: Insert your code\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        \n",
    "         # 🔶 TODO: Insert your code: Loss Calculation\n",
    "        loss = ...\n",
    "        # 🔶 TODO: Insert your code: Score Calculation\n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_accuracy', ...)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx) -> None:\n",
    "        # 🔶 TODO: Insert your code\n",
    "        self.log('validation_accuracy', ...)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx) -> None:\n",
    "        # 🔶 TODO: Insert your code\n",
    "        self.log('test_accuracy', ...)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = ...  # 🔶 TODO: Insert your code \n",
    "        return optimizer\n",
    "\n",
    "experiment = MNISTExperiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a lightning `Trainer`:\n",
    "    - Maximum epoch = 20\n",
    "    - accelerator = 'auto'\n",
    "    - Use `CSVLogger` and `TensorBoardLogger`\n",
    "    - Use `EarlyStopping` with patience epoch = 3\n",
    "    - Use `TQDMProgressBar` with refresh rate = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    ...  # 🔶 Insert your code\n",
    "    # HINT: check docs of pytorch lightning Trainer, and understand its flags.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Results (4 Points)\n",
    "- Train and test the `RawModel` and plot the score and loss values versus epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 🔶 Insert your code\n",
    "# HINT: trainer.fit(...) and trainer.test(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Re-design the model with `Dropout` layer in-between the convolutional layers and re-train the model. as like `RawModel` and create a new module as `ModelWithDropout`. Try:\n",
    "    - dropout probability = 0.1\n",
    "    - dropout probability = 0.5\n",
    "    - dropout probability = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 🔶 Insert your code\n",
    "# HINT: \n",
    "# re-create a new model class like 'class RawModel(torch.nn.Module)'. \n",
    "# add Dropout layers.\n",
    "# then run trainer.fit(...) and trainer.test(...) with this new model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Re-design the model with `BatchNorm` layer in-between the convolutional layers and re-train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 🔶 Insert your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Conclusion (3 Point)\n",
    "Comment on your findings:\n",
    "- Which method is better? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: ... # 🔶 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are the results statistically significant? If not, how can we get significant ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: ... # 🔶 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comment on different normalization techniques: `BatchNorm`, `LayerNorm` , `InstanceNorm` and `GroupNorm`. Explain the purpose of usage of them in general (for the RGB datasets, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: ... # 🔶 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Explain the operations of the `Dropout` layer in training and testing phase. Is there any difference, or are they always the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: ... # 🔶 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Explain the difference between `AdamW` and `Adam` optimizers in a few sentences.\n",
    "\n",
    "Hint: https://arxiv.org/abs/1711.05101 for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: ... # 🔶 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare the Kaiming (He) and Xavier (Glorot) Initialization techniques and explain their differences in a few sentences. \n",
    "\n",
    "Hint: You can find more information from their original papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: ... # 🔶 TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
