---
title: "04 Estimation"
subtitle: "STA120: Introduction to Statistics
         Spring semester 2024
         IMath, University of Zurich, Switzerland"
author: "Reinhard Furrer with contributions of various others"
date: "March 6, 2023"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Bias of sigma2 estimator. Lecture I
```{r}
set.seed(5)
n <- 5

sigma2 <- function(x){
  return(sum((x - mean(x))^2)/n)
}

x <- matrix(rnorm(n*100000),nrow = 100000)
sigma2s <- apply(x,1,sigma2)
mean(sigma2s)
```

```{r}
set.seed(5)
n <- 5

sigma2 <- function(x){
  return(sum((x - 0)^2)/n)
}

x <- matrix(rnorm(n*100000),nrow = 100000)
sigma2s <- apply(x,1,sigma2)
mean(sigma2s)
```


```{r}
set.seed(5)
n <- 5

sigma2 <- function(x){
  return(sum((x - mean(x))^2)/(n-1))
}

x <- matrix(rnorm(n*100000),nrow = 100000)
sigma2s <- apply(x,1,sigma2)
mean(sigma2s)
```

### Example 1 of a function. Lecture II
```{r cars}
mean.normal <- function(N){ #mean.normal is a name of the function,
  #which we will be able to run later. It takes one argument called N.
  samples <- rnorm(N)
  return(mean(samples))
}

my_mean <- mean.normal(5)
print(my_mean)
```

### Example2 of a function. Lecture III
```{r}
hist.mean.normal <- function(N,n){
  means <- numeric(0)
  for (i in c(1:n)){
    samples <- rnorm(N)
    means[i] <- mean(samples)
  }
  hist(means)
}

hist.mean.normal(50,20)
```

### Resampling in R. Lecture IV
```{r}
set.seed(10)
my_vector <- runif(n = 20, min = 0, max = 10)

my_index <- sample(x = c(1:10), size = 10, replace = FALSE)
my_index_replace <- sample(x = c(1:10), size = 10, replace = TRUE)

my_vector
my_index
my_vector[my_index] # the 10 random elements from the vector
my_vector[-my_index] # the remaining elements of the vector

which(my_vector>8)
my_vector[which(my_vector > 8)]
```


### Confidence intervals in R. Lecture V
Let's considers an artificial data set describing sleep time. We assume the sleep time follows a normal distribution. We would like to find a 95% CI for the parameter mu.
```{r}

x <- c(6.7, 8.6, 7.9, 6.4, 7.3, 6.6)

# a) exact (using the t-distribution)
n <- length(x) 
ci_lower <- mean(x)-qt(0.975, n-1)*sd(x)/sqrt(n)
ci_upper <- mean(x)+qt(0.975, n-1)*sd(x)/sqrt(n)
#Or, equvalently to return lower and upper bound of a CI:
ci = mean(x) + c(-1, 1) * qt(0.975, n - 1) * sd(x)/sqrt(n)

# b) approximated (using the normal approximation) 
ci_approx_l <- mean(x)-qnorm(0.975)*sd(x)/sqrt(n)
ci_approx_u <- mean(x)+qnorm(0.975)*sd(x)/sqrt(n)
#or:
ci_approx <- mean(x) + c(-1, 1) * qnorm(0.975) * sd(x)/sqrt(n)
# c) bootstrapped. It is too small sample size for bootstrapping.
# Here just as an example how to compute the bootstrapping CI
N <- 1000
boot_mu <- numeric(N)
for (i in 1:N){
  boot_mu[i] <- mean(sample(x, 6, replace = TRUE))
}

ci_boot <- quantile(boot_mu, c(0.025, 0.975))
hist(boot_mu, breaks = 20)


```

### R-Code/Figure: 
### 
```{r}
par( mfcol=c(1,2)) 
diam <- 28:40    # diameters   
imi  <- c(0, 3, 7, 14, 32, 20, 18, 4, 1, 1, 0, 0 ,0)  # frequencies
mero <- c(0, 0, 0, 0,  2, 9, 33, 20, 17, 9, 6, 4, 0) 
barplot( imi,  names.arg=paste(diam), main="Imipenem")
barplot( mero, names.arg=paste(diam), main="Meropenem") 
imiDat <- rep(diam, imi)   # now a vector with the 100 diameters
c( mean(imiDat), sum( mero*diam)/100)  # means for both, then spread  
c( var( imiDat), sum( (imiDat-mean(imiDat))^2)/(length(imiDat)-1) )
c( sd( imiDat), sqrt( var( imiDat)))  
```
      


### R-Code/Figure:
### 100 rate estimates. Lecture VI
```{r}
set.seed(14)            # we work reproducible
n <- 25                 # sample size
R <- 100                # number of estimates
lambda <- 1/2           # true value to estimate
samples <- matrix( rexp( n*R, rate=lambda), n, R)
lambdas <- 1/colMeans( samples)  # actual estimates
hist( lambdas, main='')          # unimodel, but not quite symmetric 
abline( v=c(lambda, mean(lambdas), median(lambdas)), col=c(3,2,4))
quantile(lambdas, probs=c(.05,.95))  
```



### R-Code/Figure: 
### Normal and $t$-based confidence intervals
```{r}
par( mfcol=c(3,1))
set.seed( 1)     # important to reconstruct the same CIs
ex.n <- 100      # 100 confidence intervals 
alpha <- .05     # 95\% confidence intervals
n <- 4           # sample size 
mu <- 0          # mean 
sigma <- 1       # standard deviation
sample <- matrix( rnorm( ex.n * n, mu, sigma), n, ex.n)  # sample used
yl <- mu + c( -6, 6)*sigma/sqrt(n)      # same y-axis for all 3 panels
ybar <- apply( sample, 2, mean)         # mean for each sample
# First panel: sigma known:
sigmaybar <- sigma/sqrt(n)
plot( 1:ex.n, 1:ex.n, type='n', ylim=yl, xaxt='n', ylab='', 
     main=bquote(sigma~known))
abline( h=mu)
for ( i in 1:ex.n){     # draw the individual CIs with appropriate color
  ci <- ybar[i] + sigmaybar * qnorm(c(alpha/2, 1-alpha/2))
  lines( c(i,i), ci, col=ifelse( ci[1]>mu|ci[2]<mu, 2, 1))
}
# Second panel: sigma unknown, normal approx:
sybar <- apply(sample, 2, sd)/sqrt(n)   # estimate the standard deviation
plot( 1:ex.n, 1:ex.n, type='n', ylim=yl, xaxt='n', ylab='',
     main=bquote("Gaussian approximation"))
abline( h=mu)
for ( i in 1:ex.n){   # similar but with individual standard deviation   
  ci <- ybar[i] + sybar[i] * qnorm(c(alpha/2, 1-alpha/2))
  lines( c(i,i), ci, col=ifelse( ci[1]>mu | ci[2]<mu, 2, 1))
}
# Third panel: sigma unknown, t-based:
plot(1:ex.n, 1:ex.n, type='n', ylim=yl, xaxt='n', ylab='',
     main='t-distribution')
abline( h=mu)
for ( i in 1:ex.n){  # similar but with t-quantile 
  ci <- ybar[i] + sybar[i] * qt(c(alpha/2, 1-alpha/2), n-1)
  lines( c(i,i), ci, col=ifelse( ci[1]>mu | ci[2]<mu, 2, 1))
}
```      
      

## 
## 
## ### Example:
## ### Calculate coverage probability
## 1-2*uniroot(function(p) qt(p, 3)-qnorm(.025),c(0,1))$root

########################################################################
# Reinhard Furrer, Spring 2021